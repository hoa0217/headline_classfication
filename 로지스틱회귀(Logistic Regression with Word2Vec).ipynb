{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv( 'data_clean.csv' )\n",
    "train_data = train_data[train_data['text'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>according gran company plans move production r...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technopolis plans develop stages area less squ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>international electronic industry company elco...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new production plant company would increase ca...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>according company updated strategy years baswa...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>london marketwatch share prices ended lower lo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>rinkuskiai beer sales fell per cent million li...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>operating profit fell eur mn eur mn including ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>net sales paper segment decreased eur mn secon...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>sales finland decreased january sales outside ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4845 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "0     according gran company plans move production r...   neutral\n",
       "1     technopolis plans develop stages area less squ...   neutral\n",
       "2     international electronic industry company elco...  negative\n",
       "3     new production plant company would increase ca...  positive\n",
       "4     according company updated strategy years baswa...  positive\n",
       "...                                                 ...       ...\n",
       "4841  london marketwatch share prices ended lower lo...  negative\n",
       "4842  rinkuskiai beer sales fell per cent million li...   neutral\n",
       "4843  operating profit fell eur mn eur mn including ...  negative\n",
       "4844  net sales paper segment decreased eur mn secon...  negative\n",
       "4845  sales finland decreased january sales outside ...  negative\n",
       "\n",
       "[4845 rows x 2 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(train_data['text'])\n",
    "sentiments = list(train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentiments)):\n",
    "    if sentiments[i]=='neutral':\n",
    "        sentiments[i]=1\n",
    "    elif sentiments[i]=='negative':\n",
    "        sentiments[i]=0\n",
    "    elif sentiments[i]=='positive':\n",
    "        sentiments[i]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for t in text :\n",
    "    sentences.append(t.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 36\n",
    "min_word_count = 3\n",
    "num_workers = 3    \n",
    "context = 10          \n",
    "downsampling = 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "   level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-14 01:33:24,594 : INFO : collecting all words and their counts\n",
      "2020-06-14 01:33:24,595 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-06-14 01:33:24,606 : INFO : collected 8951 word types from a corpus of 59521 raw words and 4845 sentences\n",
      "2020-06-14 01:33:24,607 : INFO : Loading a fresh vocabulary\n",
      "2020-06-14 01:33:24,614 : INFO : effective_min_count=3 retains 3134 unique words (35% of original 8951, drops 5817)\n",
      "2020-06-14 01:33:24,615 : INFO : effective_min_count=3 leaves 52362 word corpus (87% of original 59521, drops 7159)\n",
      "2020-06-14 01:33:24,623 : INFO : deleting the raw counts dictionary of 8951 items\n",
      "2020-06-14 01:33:24,624 : INFO : sample=0.001 downsamples 34 most-common words\n",
      "2020-06-14 01:33:24,625 : INFO : downsampling leaves estimated 47120 word corpus (90.0% of prior 52362)\n",
      "2020-06-14 01:33:24,640 : INFO : estimated required memory for 3134 words and 36 dimensions: 2469592 bytes\n",
      "2020-06-14 01:33:24,641 : INFO : resetting layer weights\n",
      "2020-06-14 01:33:25,203 : INFO : training model with 3 workers on 3134 vocabulary and 36 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-06-14 01:33:25,233 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-14 01:33:25,236 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-14 01:33:25,239 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-14 01:33:25,240 : INFO : EPOCH - 1 : training on 59521 raw words (47144 effective words) took 0.0s, 1544596 effective words/s\n",
      "2020-06-14 01:33:25,275 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-14 01:33:25,277 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-14 01:33:25,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-14 01:33:25,281 : INFO : EPOCH - 2 : training on 59521 raw words (47082 effective words) took 0.0s, 1756594 effective words/s\n",
      "2020-06-14 01:33:25,312 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-14 01:33:25,316 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-14 01:33:25,318 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-14 01:33:25,319 : INFO : EPOCH - 3 : training on 59521 raw words (47219 effective words) took 0.0s, 1455364 effective words/s\n",
      "2020-06-14 01:33:25,352 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-14 01:33:25,356 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-14 01:33:25,362 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-14 01:33:25,363 : INFO : EPOCH - 4 : training on 59521 raw words (47102 effective words) took 0.0s, 1263445 effective words/s\n",
      "2020-06-14 01:33:25,399 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-14 01:33:25,404 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-14 01:33:25,407 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-14 01:33:25,408 : INFO : EPOCH - 5 : training on 59521 raw words (47128 effective words) took 0.0s, 1331521 effective words/s\n",
      "2020-06-14 01:33:25,410 : INFO : training on a 297605 raw words (235675 effective words) took 0.2s, 1144020 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers,\n",
    "           size=num_features, min_count = min_word_count,\n",
    "            window = context, sample = downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(words, model, num_features):\n",
    "    feature_vector = np.zeros((num_features),dtype=np.float32)\n",
    "\n",
    "    num_words = 0\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "\n",
    "    for w in words:\n",
    "        if w in index2word_set:\n",
    "            num_words += 1\n",
    "            feature_vector = np.add(feature_vector, model[w])\n",
    "\n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(reviews, model, num_features):\n",
    "    dataset = list()\n",
    "\n",
    "    for s in reviews:\n",
    "        dataset.append(get_features(s, model, num_features))\n",
    "\n",
    "    reviewFeatureVecs = np.stack(dataset)\n",
    "    \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wjdwn\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\wjdwn\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "test_data_vecs = get_dataset(sentences, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3449 0\n",
      "3449 1\n",
      "3449 2\n",
      "3449 3\n",
      "3449 4\n",
      "3449 5\n",
      "3449 6\n",
      "3449 7\n",
      "3449 8\n",
      "3449 9\n",
      "3449 10\n",
      "3449 11\n",
      "3449 12\n",
      "3449 13\n",
      "3449 14\n",
      "3449 15\n",
      "3449 16\n",
      "3449 17\n",
      "3449 18\n",
      "3449 19\n",
      "3449 20\n",
      "3449 21\n",
      "3449 22\n",
      "3449 23\n",
      "3449 24\n",
      "3449 25\n",
      "3449 26\n",
      "3449 27\n",
      "3449 28\n",
      "3449 29\n",
      "3449 30\n",
      "3449 31\n",
      "3449 32\n",
      "3449 33\n",
      "3449 34\n",
      "3449 35\n",
      "4804 0\n",
      "4804 1\n",
      "4804 2\n",
      "4804 3\n",
      "4804 4\n",
      "4804 5\n",
      "4804 6\n",
      "4804 7\n",
      "4804 8\n",
      "4804 9\n",
      "4804 10\n",
      "4804 11\n",
      "4804 12\n",
      "4804 13\n",
      "4804 14\n",
      "4804 15\n",
      "4804 16\n",
      "4804 17\n",
      "4804 18\n",
      "4804 19\n",
      "4804 20\n",
      "4804 21\n",
      "4804 22\n",
      "4804 23\n",
      "4804 24\n",
      "4804 25\n",
      "4804 26\n",
      "4804 27\n",
      "4804 28\n",
      "4804 29\n",
      "4804 30\n",
      "4804 31\n",
      "4804 32\n",
      "4804 33\n",
      "4804 34\n",
      "4804 35\n"
     ]
    }
   ],
   "source": [
    "arr=[]\n",
    "for i in range(len(test_data_vecs)):\n",
    "    for j in range(len(test_data_vecs[i])):\n",
    "        if np.isnan(test_data_vecs[i][j]):\n",
    "            print(i,j)\n",
    "            if i not in arr:\n",
    "                arr.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3449, 4804]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for i in range(len(test_data_vecs)):\n",
    "    if i not in arr:\n",
    "        X.append(test_data_vecs[i])\n",
    "        y.append(sentiments[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lgs = LogisticRegression(class_weight='balanced')\n",
    "lgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.565531\n"
     ]
    }
   ],
   "source": [
    "predicted = lgs.predict(X_test)\n",
    "print(\"Accuracy: %f\" % lgs.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
